{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Implementation the logistic discrimination algorithm for multiple classes "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iris Dataset \n",
    "\n",
    "Popular classification dataset with 3 labels/classes which refer to three species of Iris (Iris setosa, Iris virginica and Iris versicolor). There are four features were measured from each sample.\n",
    "https://archive.ics.uci.edu/ml/datasets/iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SepalLengthCm</th>\n",
       "      <th>SepalWidthCm</th>\n",
       "      <th>PetalLengthCm</th>\n",
       "      <th>PetalWidthCm</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm      Species\n",
       "0            5.1           3.5            1.4           0.2  Iris-setosa\n",
       "1            4.9           3.0            1.4           0.2  Iris-setosa\n",
       "2            4.7           3.2            1.3           0.2  Iris-setosa\n",
       "3            4.6           3.1            1.5           0.2  Iris-setosa\n",
       "4            5.0           3.6            1.4           0.2  Iris-setosa"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "import pandas as pd\n",
    "data= pd.read_csv(\"iris.data\",names=[\"SepalLengthCm\",\"SepalWidthCm\", \"PetalLengthCm\",\"PetalWidthCm\",\"Species\"])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total classes:  [0 1 2]\n"
     ]
    }
   ],
   "source": [
    "data['Class']=data['Species']\n",
    "data['Class'] = data['Class'].map({'Iris-setosa': 0, 'Iris-versicolor': 1, 'Iris-virginica': 2})\n",
    "print(\"Total classes: \", data['Class'].unique())\n",
    "#data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150\n"
     ]
    }
   ],
   "source": [
    "M = []\n",
    "X = []\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "for i in range(0, len(data)):\n",
    "    if(data['Class'][i] == 0): M.append([1,0,0])\n",
    "    elif(data['Class'][i] == 1): M.append([0,1,0])\n",
    "    elif(data['Class'][i] == 2): M.append([0,0,1])\n",
    "    \n",
    "    \n",
    "    X.append([data['SepalLengthCm'][i], data['SepalWidthCm'][i], data['PetalLengthCm'][i], data['PetalWidthCm'][i]])\n",
    "\n",
    "y_train = np.asarray(M)    \n",
    "\n",
    "N = len(X)\n",
    "#print(N)\n",
    "K = len(data['Class'].unique())  #number of classes\n",
    "#print(K)\n",
    "D = len(X[0]) #dimension or number of independent variables\n",
    "\n",
    "x= np.asarray(X)\n",
    "#print(x)\n",
    "np.random.shuffle(x)\n",
    "N=x.shape[0]\n",
    "print(N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trainand test splitting for performance measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train:  (120, 4)\n",
      "Shape of X_test:  (30, 4)\n"
     ]
    }
   ],
   "source": [
    "#Data splitting for training and testing set\n",
    "training_idx = np.random.randint(x.shape[0], size=120)\n",
    "test_idx = np.random.randint(x.shape[0], size=30)\n",
    "X_train, X_test= x[training_idx,:], x[test_idx,:]\n",
    "print(\"Shape of X_train: \", X_train.shape)\n",
    "print(\"Shape of X_test: \", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation of the logistic discrimination algorithm for multiple classes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def log_regression_multi_class(x, r, d, step_size,accuracy_stop,iterations):    \n",
    "    x0 = np.repeat(1, len(x))\n",
    "    new_x = np.c_[x0, x]\n",
    "    \n",
    "    #initialize w with zeros\n",
    "    w = np.zeros( shape = (K, d + 1) )\n",
    "    #print(\"first\", w)\n",
    "    \n",
    "    # book mentions (1 .. K) 1 to K inclusive K. exactly K numbers\n",
    "    for i in range (0, K): # will work as 0 .... K-1 = K numbers         \n",
    "        #book mentions: 0 ... d => book uses inclusive 0 to d i.e total d + 1 \n",
    "        for j in range (0, d + 1): # will work as 0 ..... d = d + 1 counts\n",
    "            w[i, j] = np.random.uniform (-0.01, 0.01)\n",
    "\n",
    "    # run iterations time (i.e. 0 .... (iterations - 1) )\n",
    "    for test in range(0, iterations):\n",
    "        \n",
    "        # accuracy score for current iterations\n",
    "        accuracy_score = 0\n",
    "        \n",
    "        # initialize delta_w i.e derivative_w i.e deriv_w\n",
    "        deriv_w = np.zeros( shape = (K, d + 1 ) )\n",
    "        \n",
    "        # iterate for all rows of x where each row represent x0, x1, .... xd i.e. d + 1 elements in a single row\n",
    "        \n",
    "        # book: 1 .... N i.e. total N count\n",
    "        N = len(new_x)\n",
    "        for t in range(0, N ): # i.e. 0 .... N - 1\n",
    "            \n",
    "            # calculate o. o will help to calculate sigmoid/softmax i.e. to calculate y\n",
    "            o = []\n",
    "            for i in range(0, K):\n",
    "                o.append(0)\n",
    "                for j in range(0, d + 1):\n",
    "                    o[i] += w[i, j] * new_x[t, j]\n",
    "            \n",
    "            # o2 also helps in calculating sigmoid/softmax i.e. to calculate y\n",
    "            # see the equation y = exp(Oi)/ ( sum of  exp(Ok) for all K 1....k )\n",
    "            # o2 helps to calculate the denominator\n",
    "            y = []            \n",
    "            o2 = 0\n",
    "            for i in range(0, K):\n",
    "                o2 += np.exp(o[i])\n",
    "            \n",
    "            # calculate y \n",
    "            for i in range(0, K):\n",
    "                y.append(0)                \n",
    "                y[i] = np.exp( o[i] )/o2\n",
    "                #print(y)\n",
    "              \n",
    "              # check accuracy score\n",
    "            if r[t , i].argmax() == y.index (max(y)):\n",
    "                accuracy_score += 1\n",
    "                          \n",
    "            # calculate deriv w\n",
    "            for i in range (0, K):\n",
    "                for j in range(0, d + 1 ): # book mentions: 0 to d i.e. d + 1 count\n",
    "                    deriv_w[i, j] += deriv_w[i, j] + (r[t, i] - y[i] ) * new_x[t, j]            \n",
    "            \n",
    "            # the book shows w updates after each iteration. \n",
    "            # however, if i print w at that point, w might have nans    i.e. overfit (train accuracy >= 100%)\n",
    "            # hence, even during the iteration checking for accuracy\n",
    "            # it might need further thoughts if this can be here\n",
    "            if  (  accuracy_score/ len(x) >= accuracy_stop ):\n",
    "                print ('Accuracy', accuracy_score * 100 / len(x) )\n",
    "                #print(w)\n",
    "                return (w)\n",
    "            \n",
    "\n",
    "        # after one pass of all samples calculate/update w\n",
    "        for i in range (0, K):\n",
    "            for j in range(0, d + 1):\n",
    "                w[i, j] = w[i, j] + step_size * deriv_w[i, j]\n",
    "                \n",
    "        #print('\\nw at iteration', test)\n",
    "        #print(w)\n",
    "        \n",
    "        # exit from the method if we have reached the accuracy target\n",
    "        if  (  accuracy_score/ len(x) >= accuracy_stop ):\n",
    "            print ('\\nTraining accuracy', accuracy_score * 100 / len(x) )\n",
    "            print(w)\n",
    "            return (w)\n",
    "    \n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 90.0\n",
      "\n",
      " Logistic Discrimination Weights Multi_class \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nilufa\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:45: RuntimeWarning: overflow encountered in exp\n",
      "C:\\Users\\Nilufa\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:50: RuntimeWarning: overflow encountered in exp\n",
      "C:\\Users\\Nilufa\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:50: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 4.47113426e+35,  2.44981317e+36,  1.27900326e+36,\n",
       "         1.67261539e+36,  6.29151120e+35],\n",
       "       [-2.32175096e+35, -1.27160538e+36, -6.64496694e+35,\n",
       "        -8.65711078e+35, -3.25314290e+35],\n",
       "       [-2.14938330e+35, -1.17820780e+36, -6.14506566e+35,\n",
       "        -8.06904313e+35, -3.03836830e+35]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w= log_regression_multi_class(X_train,y_train, D, 0.5,0.9,100)\n",
    "print ('\\n Logistic Discrimination Weights Multi_class ')\n",
    "w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison of sklearn libraries logistic regression function "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing sklearn libraries for logistic regression function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trainand test splitting for performance measure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Dataset:  (120, 4)\n",
      "Test Dataset:  (30, 4)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y_train, test_size = 0.2, random_state =4)\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "#print(y_train)\n",
    "\n",
    "#LogisticRegression in sklearn doesn't support multi-label directly\n",
    "Y_train = np.argmax(y_train, axis=1)\n",
    "Y_test = np.argmax(y_test, axis=1)\n",
    "print('Train Dataset: ', X_train.shape)\n",
    "print('Test Dataset: ', X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting Multiclass Logistic Classification to the Training set From sklearn libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting Multiclass Logistic Classification to the Training set\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logisticregression = LogisticRegression()\n",
    "logisticregression.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 0 2 2 2 1 2 0 0 1 0 0 0 1 2 0 1 0 0 2 0 2 1 0 0 0 0 0 0 2]\n"
     ]
    }
   ],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = logisticregression.predict(X_test)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 93.33\n"
     ]
    }
   ],
   "source": [
    "#accuracy_score(Y_test, pred) # this gives accuracy\n",
    "print('Accuracy: {}'.format(round(accuracy_score(np.array(Y_test), np.array(y_pred)) * 100, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets see the actual and predicted value side by side\n",
    "y_compare = np.vstack((Y_test,y_pred)).T\n",
    "#actual value on the left side and predicted value on the right hand side\n",
    "#printing the top 5 values\n",
    "#y_compare[:5,:]\n",
    "#print(y_compare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
